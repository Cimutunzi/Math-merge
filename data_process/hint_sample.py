import json
import os


FILE_CONFIG = {
    "data_file": "/data/qq/LLaMA-Factory/data/Qwen2.5-Math-7B/math-merge/tem_0.7/stage_3-1.jsonl",
    "eval_result_files": [
        "/data/qq/models/Qwen/Qwen2.5-Math-7B/math_eval/math-merge/Recording/qwen_math_7b_level_3_step_1-4_qwen_box_seed0_t0.7_n_sample_16.jsonl",
        "/data/qq/models/Qwen/Qwen2.5-Math-7B/math_eval/math-merge/Recording/qwen_math_7b_level_3_step_1-2_qwen_box_seed0_t0.7_n_sample_16.jsonl",
        "/data/qq/models/Qwen/Qwen2.5-Math-7B/math_eval/math-merge/Recording/qwen_math_7b_level_3_step_3-4_qwen_box_seed0_t0.7_n_sample_16.jsonl"
    ],
    "eval_source_files": [
        "/data/qq/math-evaluation-harness/data/math-merge/qwen_math_7b_level_3_step_1-4.jsonl",
        "/data/qq/math-evaluation-harness/data/math-merge/qwen_math_7b_level_3_step_1-2.jsonl",
        "/data/qq/math-evaluation-harness/data/math-merge/qwen_math_7b_level_3_step_3-4.jsonl"
    ],
    "output_file": "/data/qq/LLaMA-Factory/data/Qwen2.5-Math-7B/math-merge/tem_0.7/stage_3-3.jsonl"
}
# é…ç½®æ–‡ä»¶è·¯å¾„
# FILE_CONFIG = {
#     "data_file": "/data/qq/LLaMA-Factory/data/Qwen2.5-Math-1.5B/math-merge/tem_0.7/stage_3-1.jsonl",
#     "eval_result_files": [
#         "/data/qq/models/Qwen/Qwen2.5-Math-1.5B/math_eval/math-merge/Recording/qwen_math_1.5b_level_3_step_1-4_qwen_box_seed0_t0.7_n_sample_16.jsonl",
#         "/data/qq/models/Qwen/Qwen2.5-Math-1.5B/math_eval/math-merge/Recording/qwen_math_1.5b_level_3_step_1-2_qwen_box_seed0_t0.7_n_sample_16.jsonl",
#         "/data/qq/models/Qwen/Qwen2.5-Math-1.5B/math_eval/math-merge/Recording/qwen_math_1.5b_level_3_step_3-4_qwen_box_seed0_t0.7_n_sample_16.jsonl"
#     ],
#     "eval_source_files": [
#         "/data/qq/math-evaluation-harness/data/math-merge/qwen_math_1.5b_level_3_step_1-4.jsonl",
#         "/data/qq/math-evaluation-harness/data/math-merge/qwen_math_1.5b_level_3_step_1-2.jsonl",
#         "/data/qq/math-evaluation-harness/data/math-merge/qwen_math_1.5b_level_3_step_3-4.jsonl"
#     ],
#     "output_file": "/data/qq/LLaMA-Factory/data/Qwen2.5-Math-1.5B/math-merge/tem_0.7/stage_3-3.jsonl"
# }

# ---------------------- è¾…åŠ©å‡½æ•° ----------------------
def validate_paths():
    """éªŒè¯æ‰€æœ‰è¾“å…¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨"""
    required_files = [FILE_CONFIG["data_file"]] + FILE_CONFIG["eval_result_files"] + FILE_CONFIG["eval_source_files"]
    for path in required_files:
        if not os.path.exists(path):
            raise FileNotFoundError(f"å…³é”®æ–‡ä»¶ç¼ºå¤±: {path}")

def load_jsonl_safe(path: str) -> list:
    """å®‰å…¨åŠ è½½JSONLæ–‡ä»¶ï¼Œå¸¦å¼‚å¸¸å¤„ç†"""
    try:
        with open(path, 'r', encoding='utf-8') as f:
            return [json.loads(line) for line in f]
    except Exception as e:
        raise RuntimeError(f"åŠ è½½æ–‡ä»¶å¤±è´¥ {path}: {str(e)}")

def build_eval_maps():
    """æ„å»ºè¯„æµ‹ç»“æœå’Œæºæ•°æ®çš„å¿«é€ŸæŸ¥æ‰¾å­—å…¸"""
    eval_scores = []
    for result_file in FILE_CONFIG["eval_result_files"]:
        score_map = {}
        for item in load_jsonl_safe(result_file):
            # ç›´æ¥æ£€æŸ¥Trueæ˜¯å¦å­˜åœ¨äºscoreåˆ—è¡¨
            score_list = item.get('score', [])
            if not isinstance(score_list, list):
                print(f"è­¦å‘Šï¼šidx {item['idx']} çš„scoreå­—æ®µç±»å‹å¼‚å¸¸ ({type(score_list)})ï¼Œå·²è·³è¿‡")
                continue
            score_map[item['idx']] = True in score_list
        eval_scores.append(score_map)
    
    eval_sources = []
    for source_file in FILE_CONFIG["eval_source_files"]:
        eval_sources.append({item['idx']: item for item in load_jsonl_safe(source_file)})
    
    return eval_scores, eval_sources

# ---------------------- ä¸»é€»è¾‘ ----------------------
def main():
    validate_paths()
    
    # åŠ è½½æ•°æ®
    main_data = load_jsonl_safe(FILE_CONFIG["data_file"])
    eval_scores, eval_sources = build_eval_maps()
    
    # å¤„ç†æ•°æ®
    stats = {'replaced': [0, 0, 0], 'discarded': 0}
    updated_data = []
    
    for item in main_data:
        # è·³è¿‡ä¸éœ€è¦ä¿®å¤çš„æ•°æ®
        if item.get('accuracy', 0) != 0:
            updated_data.append(item)
            continue
        
        idx = item.get('idx')
        if idx is None:
            print(f"è­¦å‘Šï¼šå‘ç°æ— idxå­—æ®µçš„æ•°æ®é¡¹ï¼Œå·²ä¸¢å¼ƒã€‚å†…å®¹: {item}")
            stats['discarded'] += 1
            continue
        
        replaced = False
        for eval_idx in range(3):  # æŒ‰ä¼˜å…ˆçº§eval1 â†’ eval3å¤„ç†
            # æ£€æŸ¥è¯„æµ‹æ˜¯å¦é€šè¿‡
            if not eval_scores[eval_idx].get(idx, False):
                continue
            
            # è·å–æºæ•°æ®
            source = eval_sources[eval_idx].get(idx)
            if not source:
                print(f"è­¦å‘Šï¼ševal{eval_idx+1} idx {idx} è¯„æµ‹é€šè¿‡ä½†æºæ•°æ®ç¼ºå¤±")
                continue
            
            # æ‰§è¡Œæ›¿æ¢
            try:
                new_item = item.copy()
                new_item['question'] = source['problem']
                new_item['answer'] = source['answer_end']
                updated_data.append(new_item)
                stats['replaced'][eval_idx] += 1
                replaced = True
                break  # æ‰¾åˆ°æœ‰æ•ˆæ›¿æ¢å³ç»ˆæ­¢
            except KeyError as e:
                print(f"é”™è¯¯ï¼ševal{eval_idx+1} idx {idx} æºæ•°æ®ç¼ºå¤±å­—æ®µ {e}")
        
        if not replaced:
            stats['discarded'] += 1
    
    # ä¿å­˜ç»“æœ
    with open(FILE_CONFIG["output_file"], 'w', encoding='utf-8') as f:
        for item in updated_data:
            f.write(json.dumps(item, ensure_ascii=False) + '\n')
    
    # æ‰“å°æŠ¥å‘Š
    print("\nâœ… å¤„ç†å®Œæˆï¼ç»Ÿè®¡å¦‚ä¸‹ï¼š")
    print(f"  ä» eval1 æ›¿æ¢: {stats['replaced'][0]}")
    print(f"  ä» eval2 æ›¿æ¢: {stats['replaced'][1]}")
    print(f"  ä» eval3 æ›¿æ¢: {stats['replaced'][2]}")
    print(f"âŒ ä¸¢å¼ƒæ€»æ•°: {stats['discarded']}")
    print(f"ğŸ“¦ æœ€ç»ˆæ•°æ®é‡: {len(updated_data)}/{len(main_data)}")

if __name__ == "__main__":
    main()